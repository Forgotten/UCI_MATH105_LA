{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 6\n",
    "\n",
    "Name: \n",
    "\n",
    "Collaborators:\n",
    "\n",
    "due November 18th, 2015\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We want to solve the linear system given by \n",
    "\\begin{equation}\n",
    "Ax = b,\n",
    "\\end{equation}\n",
    "where $A$ is a non-singular $n\\times n$ matrix. \n",
    "\n",
    "You have already solved this problem using Gaussian Elimination (and its partial pivoted version) which has an assymptotic cost $\\mathcal{O}(n^3)$. \n",
    "\n",
    "In this homework you will try to solve the system in lower complexity using an iterative method. In particular, you will implement the Jacobi and Gauss-Seidel iterations and you will study its limitations.\n",
    "\n",
    "Both Jacobi and Gauss-Iterations can be seen as fixed point methods, used by a matrix splitting. \n",
    "\n",
    "#### Matrix Splitting\n",
    "\n",
    "Given a square matrix $A$ you will define a splitting in two matrices $N$ and $M$ such that $A = N+M$.\n",
    "If you suppose that $N$ is invertible you can write the system \n",
    "\\begin{equation}\n",
    "Ax = b,\n",
    "\\end{equation}\n",
    "as \n",
    "\\begin{equation}\n",
    "Nx =  b - Mx,\n",
    "\\end{equation}\n",
    "and you can define the fixed point iteration as\n",
    "\\begin{equation}\n",
    "Nx^{n+1} =  b - Mx^{n},\n",
    "\\end{equation}\n",
    "or equivalently\n",
    "\\begin{equation}\n",
    "x^{n+1} = N^{-1}\\left ( b - Mx^{n} \\right),\n",
    "\\end{equation}\n",
    "in which the inverse of $N$ is never computed explicitily. \n",
    "\n",
    "In this case you can show that the convergence speed is can be determined from the spectral radius of the iteration matrix:\n",
    "\\begin{equation}\n",
    "T =  N^{-1}M.\n",
    "\\end{equation}\n",
    "\n",
    "#### Convergence rate\n",
    "\n",
    "If we define \n",
    "\\begin{equation}\n",
    "f(x) :=  N^{-1}\\left ( b - Mx^{n} \\right),\n",
    "\\end{equation}\n",
    "then we are solving the fixed point problem \n",
    "\\begin{equation}\n",
    "x = f(x).\n",
    "\\end{equation}\n",
    "\n",
    "We know that in this case, the fixed point iteration given by $x^{n+1} = f(x^n)$ converges if and only if there exist $\\kappa <1$ such that \n",
    "\\begin{equation}\n",
    "\\| f(x) - f(y) \\| \\leq \\kappa \\|x - y\\|, \\qquad \\forall x,y \\in R^n,\n",
    "\\end{equation}\n",
    "where we are using the Euclidean metric given by \n",
    "\\begin{equation}\n",
    "\\| x \\| = \\sqrt{\\sum_{i = 1}^n |x_i|^2 }.\n",
    "\\end{equation}\n",
    "\n",
    "In such case, the error is given by \n",
    "\\begin{equation}\n",
    "\\| x^{n+1} - x\\| \\leq \\frac{\\kappa^{n+1}}{1 - \\kappa} \\| x^{0} - x\\|,\n",
    "\\end{equation}\n",
    "in other words, the convergence and its ratio ar given by $\\kappa$.\n",
    "\n",
    "\n",
    "Using the expression for $f$ we have that\n",
    "\\begin{align}\n",
    "  \\| f(x) - f(y) \\| & = \\| N^{-1}(b - Mx) - N^{-1}(b - My)  \\|, \\\\\n",
    "                    & = \\| N^{-1} M(x -y)  \\|, \\\\\n",
    "                    & \\leq \\|N^{-1} M \\| \\|x - y \\|;\n",
    "\\end{align}\n",
    "or \n",
    "\\begin{equation}\n",
    "\\kappa = \\|N^{-1} M \\| = \\|T \\|.\n",
    "\\end{equation}\n",
    "\n",
    "When we are using the Euclidean norm, we have that \n",
    "\\begin{equation}\n",
    "\\|T \\| = \\max_{z \\neq 0} \\frac{\\|Tz \\|}{\\| z\\|} = \\rho(T).\n",
    "\\end{equation}\n",
    "where the spectral radius $\\rho(T)$ is given by \n",
    "\\begin{equation}\n",
    "\\rho(T) = \\max_{i = 1,..,n} |\\lambda_i|, \\qquad \\mbox{ where } \\lambda_i \\mbox{ are the eigenvalues of } T\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Jacobi Iteration\n",
    "\n",
    "The Jacobi iteration correspond to a fixed point method, in which the Matrix splitting is given by \n",
    "\\begin{equation}\n",
    "N = D, \\qquad M= L+U,\n",
    "\\end{equation}\n",
    "where $D$ is the diagonal of $A$ and $L$ and $U$ are the (strictly) upper and lower triangular parts of $A$.\n",
    "\n",
    "In order to extract the diagonal, upper triangular and lower triangular matrices from $A$ we will use the built-in functions in Julia. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in the splitting = 0.0\n"
     ]
    }
   ],
   "source": [
    "# size of the matrices\n",
    "m = 10\n",
    "# generate a random matrix\n",
    "A = rand(m,m) + m*eye(m)\n",
    "# get the digonal part\n",
    "D = diagm(diag(A),0)\n",
    "# to get the upper triangular part of the matrix\n",
    "U = triu(A,1)\n",
    "#and the lower part \n",
    "L = tril(A,-1)\n",
    "# we check that this is indeed a matrix splitting\n",
    "println(\"Error in the splitting = \",norm(A -(L+D+U)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging and testing your functions you may find the macro @show usefull, if you type @show at the beginning of a line, it will force julia to show in the console the command, and what it is doing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.a Implement the Jacobi iteration with input:\n",
    "- $A$ a square matrix,\n",
    "- $b$ a vector <br>\n",
    "\n",
    "Your function will have the following optional parameters\n",
    "- $Nmax$ maximum number of iterations, by default set to 30\n",
    "- $\\epsilon$ the tolerance, by default set to 1e-6\n",
    "- history this is a boolean to return all the succesive approximations <br> \n",
    "\n",
    "The ouput of your function is the final approximation $x$ of your vector, of in the case that history is true, it will output a matrix with the all the intermediate approximations of size $ n \\times \\mbox{number of iterations to converge}$.\n",
    "\n",
    "Your function will raise an error if it didn't converge in the $Nmax$ iterations, and if the dimension of $A$ and $b$ are not consistent.\n",
    "\n",
    "Hint:\n",
    "- to build the matrix with the intermediat steps you can use hcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function JacobiIt(A,b; Nmax = 30, 系=1e-6, history = false)\n",
    "   \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Gauss-Seidel iteration\n",
    "\n",
    "The Gauss-Seidel iteration is analogous to the Jacobi iteration; however, it uses a different splitting, \n",
    "namely \n",
    "\\begin{equation}\n",
    "N = D+U, \\qquad M= L,\n",
    "\\end{equation}\n",
    "\n",
    "Q1.a Implement the Gauss-Seidel iteration with input:\n",
    "- $A$ a square matrix,\n",
    "- $b$ a vector <br>\n",
    "\n",
    "Your function will have the following optional parameters\n",
    "- $Nmax$ maximum number of iterations, by default set to 30\n",
    "- $\\epsilon$ the tolerance, by default set to 1e-6\n",
    "- history this is a boolean to return all the succesive approximations <br> \n",
    "\n",
    "The ouput of your function is the final approximation $x$ of your vector, of in the case that history is true, it will output a matrix with the all the intermediate approximations of size $ n \\times \\mbox{number of iterations to converge}$\n",
    "\n",
    "Your function will raise an error if it didn't converge in the $Nmax$ iterations, and if the dimension of $A$ and $b$ are not consistent.\n",
    "\n",
    "Hint:\n",
    "- to build the matrix with the intermediat steps you can use hcat\n",
    "- you can type ? hcat to get the built-in help\n",
    "- you won't compute the inverse inv(N) explicitly, you will use a triangular solver by \"\\\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function GaussSeidelIt(A,b; Nmax = 30, 系=1e-6, history = false)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Comparison \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you will need to compute the spectral radius of matrices, for a matrix $A$, its spectral radius $\\rho (A)$ can be computed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.1490693054511"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating random matrix of size m \\times m\n",
    "m = 100\n",
    "A = rand(m,m) + m*eye(m)\n",
    "\n",
    "# computing the eigenvalues and eigenvectors of A\n",
    "(位, X) = eig(A)\n",
    "\n",
    "# obtaining the one with the maximum absolute value\n",
    "rhoA = maximum(abs(位))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your algorithms to solve the following randomly generated system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 100\n",
    "A = rand(m,m) + m*eye(m)\n",
    "b = rand(m,1)\n",
    "\n",
    "@time XJac = JacobiIt(A,b, history = true)\n",
    "println(\"The residual is : \", norm(A*XJac[:,end]- b)/norm(b) )\n",
    "println(\"number of iterations is : \",size(XJac,2))\n",
    "\n",
    "@time XGS = GaussSeidelIt(A,b, history = true)\n",
    "println(\"The residual is : \", norm(A*XGS[:,end]- b)/norm(b) )\n",
    "println(\"number of iterations is : \",size(XGS,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.a How can you explain the one converges faster than the other? Write a small script that computes the spectral radius of the iteration matrix for both algorithms and use it on your explanation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your script in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will use your algorithms to solve a slighly different system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 100;\n",
    "A = rand(m,m) + sqrt(m)*eye(m);\n",
    "b = rand(m,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Jacobi iteration, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time XJac = JacobiIt(A,b, history = true)\n",
    "println(\"number of iterations is : \",size(XJac,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and with the Gauss Seidel iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time XGS = GaussSeidelIt(A,b, history = true)\n",
    "println(\"number of iterations is : \",size(XGS,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.b How can you explain the one converges and the other just fails? Write a small script that computes the spectral radius of the iteration matrix for both algorithms and use it on your explanation. \n",
    "Hint: \n",
    "- you may need to increase the number of iterations, Nmax = 60 should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write your script in here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Complexity (bonus) (10 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.a What is the complexity of one iteration of the Gauss-Seidel method? what about complexity of the one iteration of the Jacobi? What would be the complexity the matrix was sparse? Can you easily parallelize the Jacobi iteration? what about Gauss Seidel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.b What would be the condition on the number of iterations such that the Jacobi and Gauss-Seidel iteration would have a better complexity than Gaussian Elimination?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.c Run a benchmark with the randomly generated systems that you use to test your functions. Can you achieve a complexity $\\mathcal{O}(n^2)$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write your whole script here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.10",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
